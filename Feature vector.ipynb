{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d94a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "import os\n",
    "from pandas import DataFrame\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e84f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [\"pathway\", \"target\", \"enzyme\", \"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5c7ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 572\n",
    "batch_size = 256\n",
    "epo_num = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c30435",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drug = pd.read_csv(\"drug_features.csv\")\n",
    "extraction = pd.read_csv(\"extraction.csv\")\n",
    "mechanism = extraction[\"mechanism\"]\n",
    "action = extraction[\"action\"]\n",
    "drugA = extraction[\"drugA\"]\n",
    "drugB = extraction[\"drugB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6138f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_vector(feature_name, df):\n",
    "    def Jaccard(matrix):\n",
    "        matrix = np.mat(matrix)\n",
    "\n",
    "        numerator = matrix * matrix.T\n",
    "\n",
    "        denominator = (\n",
    "            np.ones(np.shape(matrix)) * matrix.T\n",
    "            + matrix * np.ones(np.shape(matrix.T))\n",
    "            - matrix * matrix.T\n",
    "        )\n",
    "\n",
    "        return numerator / denominator\n",
    "\n",
    "    all_feature = []\n",
    "    drug_list = np.array(df[feature_name]).tolist()\n",
    "    # Features for each drug, for example, when feature_name is target, drug_list=[\"P30556|P05412\",\"P28223|P46098|……\"]\n",
    "    for i in drug_list:\n",
    "        for each_feature in i.split(\"|\"):\n",
    "            if each_feature not in all_feature:\n",
    "                all_feature.append(each_feature)  # obtain all the features\n",
    "    #print(\"length of all feature is\", len(all_feature))\n",
    "    feature_matrix = np.zeros((len(drug_list), len(all_feature)), dtype=float)\n",
    "    df_feature = DataFrame(\n",
    "        feature_matrix, columns=all_feature\n",
    "    )  # Consrtuct feature matrices with key of dataframe\n",
    "    for i in range(len(drug_list)):\n",
    "        for each_feature in df[feature_name].iloc[i].split(\"|\"):\n",
    "            df_feature[each_feature].iloc[i] = 1\n",
    "\n",
    "    df_feature = np.array(df_feature)\n",
    "    sim_matrix = np.array(Jaccard(df_feature))\n",
    "    \n",
    "    #print(feature_name + \" len is:\" + str(len(sim_matrix[0])))\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db81fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(df_drug, feature_list, mechanism, action, drugA, drugB):\n",
    "    d_label = {}\n",
    "    d_feature = {}\n",
    "\n",
    "    # Transfrom the interaction event to number\n",
    "    d_event = []\n",
    "    for i in range(len(mechanism)):\n",
    "        d_event.append(mechanism[i] + \" \" + action[i])\n",
    "\n",
    "    count = {}\n",
    "    for i in d_event:\n",
    "        if i in count:\n",
    "            count[i] += 1\n",
    "        else:\n",
    "            count[i] = 1\n",
    "    event_num = len(count)\n",
    "    list1 = sorted(count.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i in range(len(list1)):\n",
    "        d_label[list1[i][0]] = i\n",
    "\n",
    "    vector = np.zeros(\n",
    "        (len(np.array(df_drug[\"name\"]).tolist()), 0), dtype=float\n",
    "    )  # vector=[]\n",
    "    for i in feature_list:\n",
    "        #vector = np.hstack((vector, feature_vector(i, df_drug, vector_size)))\n",
    "        tempvec = feature_vector(i, df_drug)\n",
    "        vector = np.hstack((vector, tempvec))\n",
    "    # Transfrom the drug ID to feature vector\n",
    "    for i in range(len(np.array(df_drug[\"name\"]).tolist())):\n",
    "        d_feature[np.array(df_drug[\"name\"]).tolist()[i]] = vector[i]\n",
    "\n",
    "    # Use the dictionary to obtain feature vector and label\n",
    "    new_feature = []\n",
    "    new_label = []\n",
    "\n",
    "    for i in range(len(d_event)):\n",
    "        temp = np.hstack((d_feature[drugA[i]], d_feature[drugB[i]]))\n",
    "        new_feature.append(temp)\n",
    "        new_label.append(d_label[d_event[i]])\n",
    "\n",
    "    new_feature = np.array(new_feature)  # 323539*....\n",
    "    new_label = np.array(new_label)  # 323539\n",
    "\n",
    "    return new_feature, new_label, event_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041be1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature, new_label, event_num = prepare(\n",
    "    df_drug, feature_list, mechanism, action, drugA, drugB\n",
    ")\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(new_feature)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(new_label)\n",
    "print(\"dataset len\", len(new_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06cb235",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73efbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc6f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_DDI(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_DDI, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 64, (3, 1), padding=(1, 0))\n",
    "        self.conv2 = nn.Conv2d(64, 128, (3, 1), padding=(1, 0))\n",
    "        self.conv3_1 = nn.Conv2d(128, 128, (3, 1), padding=(1, 0))\n",
    "        self.conv3_2 = nn.Conv2d(128, 128, (3, 1), padding=(1, 0))\n",
    "        self.conv4 = nn.Conv2d(128, 256, (3, 1), padding=(1, 0))\n",
    "        self.fc1 = nn.Linear(256 * 572 * 4, 256)  # Adjust feature_size based on your input dimensions\n",
    "        self.fc2 = nn.Linear(256, event_num)  # Assuming 65 DDI types\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 2, 572, 4)\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        identity = x\n",
    "        x = F.leaky_relu(self.conv3_1(x))\n",
    "        x = self.conv3_2(x)\n",
    "        x += identity\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.leaky_relu(self.conv4(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78a1300",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDIDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.len = len(x)\n",
    "        self.x_data = torch.from_numpy(x)\n",
    "\n",
    "        self.y_data = torch.from_numpy(y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0e1215",
   "metadata": {},
   "outputs": [],
   "source": [
    "class focal_loss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super(focal_loss, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, preds, labels):\n",
    "        # assert preds.dim() == 2 and labels.dim()==1\n",
    "        labels = labels.view(-1, 1).type(torch.int64)  # [B * S, 1]\n",
    "        preds = preds.view(-1, preds.size(-1))  # [B * S, C]\n",
    "\n",
    "        preds_logsoft = F.log_softmax(preds, dim=1)  # 先softmax, 然后取log\n",
    "        preds_softmax = torch.exp(preds_logsoft)  # softmax\n",
    "\n",
    "        preds_softmax = preds_softmax.gather(1, labels)  # 这部分实现nll_loss ( crossempty = log_softmax + nll )\n",
    "        preds_logsoft = preds_logsoft.gather(1, labels)\n",
    "\n",
    "        loss = -torch.mul(torch.pow((1 - preds_softmax), self.gamma),\n",
    "                          preds_logsoft)  # torch.pow((1-preds_softmax), self.gamma) 为focal loss中 (1-pt)**γ\n",
    "\n",
    "        loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf589ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "train_epochs_loss = []\n",
    "valid_epochs_loss = []\n",
    "\n",
    "def train_fn(model, x_train, y_train, x_test, y_test, event_num):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "    # optimizer = optim.RAdam(model.parameters(), lr=learn_rating, weight_decay=weight_decay_rate)\n",
    "\n",
    "    # Ranger(RAdam+LookAhead) + CosineAnnealingLR: 50epochs一个半周期\n",
    "    #optimizer = Ranger(model.parameters(), lr=learn_rating, weight_decay=weight_decay_rate, betas=(0.95, 0.999), eps=1e-6)\n",
    "    #scheduler = CosineAnnealingLR(optimizer, T_max=epo_num, eta_min=1e-6)\n",
    "\n",
    "\n",
    "    my_loss = focal_loss()\n",
    "    model = model.to(device)\n",
    "    #earlystop = EarlyStopping(patience=patience, delta=delta)\n",
    "\n",
    "    x_train = np.vstack(\n",
    "        (\n",
    "            x_train,\n",
    "            np.hstack(\n",
    "                (x_train[:, len(x_train[0]) // 2 :], x_train[:, : len(x_train[0]) // 2])\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    y_train = np.hstack((y_train, y_train))\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(x_train)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(y_train)\n",
    "\n",
    "    len_train = len(y_train)\n",
    "    len_test = len(y_test)\n",
    "    print(\"arg train len\", len(y_train))\n",
    "    print(\"test len\", len(y_test))\n",
    "\n",
    "    train_dataset = DDIDataset(x_train, np.array(y_train))\n",
    "    test_dataset = DDIDataset(x_test, np.array(y_test))\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    for epoch in range(epo_num):\n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        model.train()\n",
    "        for batch_idx, data in enumerate(train_loader, 0):\n",
    "            x, y = data\n",
    "\n",
    "            # mixup\n",
    "            lam = np.random.beta(0.5, 0.5)\n",
    "            index = torch.randperm(x.size()[0])\n",
    "            inputs = lam * x + (1 - lam) * x[index, :]\n",
    "\n",
    "            targets_a, targets_b = y, y[index]\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            targets_a = targets_a.to(device)\n",
    "            targets_b = targets_b.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward+update\n",
    "            pred = model(inputs.float())\n",
    "\n",
    "            loss = lam * my_loss(pred, targets_a) + (1 - lam) * my_loss(pred, targets_b)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        testing_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in enumerate(test_loader, 0):\n",
    "                inputs, target = data\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "                target = target.to(device)\n",
    "\n",
    "                pred = model(inputs.float())\n",
    "\n",
    "                loss = my_loss(pred, target)\n",
    "                testing_loss += loss.item()\n",
    "        # if epoch+1 % 5 == 0:\n",
    "        print(\n",
    "            \"epoch [%d] loss: %.6f testing_loss: %.6f \"\n",
    "            % (epoch + 1, running_loss / len_train, testing_loss / len_test)\n",
    "        )\n",
    "        \n",
    "        train_epochs_loss.append(running_loss / len_train)\n",
    "        valid_epochs_loss.append(testing_loss / len_test)\n",
    "        earlystop(valid_epochs_loss[-1], model, file_path)\n",
    "        if earlystop.early_stop:\n",
    "            print(\"Early stopping\\n\")\n",
    "            break\n",
    "\n",
    "\n",
    "    pre_score = np.zeros((0, event_num), dtype=float)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(test_loader, 0):\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.to(device)\n",
    "            X = model(inputs.float())\n",
    "            pre_score = np.vstack((pre_score, F.softmax(X).cpu().numpy()))\n",
    "    return pre_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088109a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(feature, label, event_num):\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    y_true = np.array([])\n",
    "    y_score = np.zeros((0, event_num), dtype=float)\n",
    "    y_pred = np.array([])\n",
    "\n",
    "    for train_index, test_index in skf.split(feature, label):\n",
    "\n",
    "        model = CNN_DDI()\n",
    "\n",
    "        X_train, X_test = feature[train_index], feature[test_index]\n",
    "        y_train, y_test = label[train_index], label[test_index]\n",
    "        print(\"train len\", len(y_train))\n",
    "        print(\"test len\", len(y_test))\n",
    "\n",
    "        pred_score = train_fn(model, X_train, y_train, X_test, y_test, event_num)\n",
    "\n",
    "        pred_type = np.argmax(pred_score, axis=1)\n",
    "        y_pred = np.hstack((y_pred, pred_type))\n",
    "        y_score = np.row_stack((y_score, pred_score))\n",
    "\n",
    "        y_true = np.hstack((y_true, y_test))\n",
    "\n",
    "    result_all, result_eve = evaluate(y_pred, y_score, y_true, event_num)\n",
    "    print(\"Training finished!\")\n",
    "\n",
    "    return result_all, result_eve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ddd458",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./\"\n",
    "result_all, result_eve = cross_val(new_feature, new_label, event_num)\n",
    "save_result(file_path, \"all\", result_all)\n",
    "save_result(file_path, \"each\", result_eve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67853c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
