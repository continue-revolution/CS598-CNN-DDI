{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_vector(feature_name, df):\n",
    "    def Jaccard(matrix):\n",
    "        matrix = np.mat(matrix)\n",
    "\n",
    "        numerator = matrix * matrix.T\n",
    "\n",
    "        denominator = (\n",
    "            np.ones(np.shape(matrix)) * matrix.T\n",
    "            + matrix * np.ones(np.shape(matrix.T))\n",
    "            - matrix * matrix.T\n",
    "        )\n",
    "\n",
    "        return numerator / denominator\n",
    "\n",
    "    all_feature = []\n",
    "    drug_list = np.array(df[feature_name]).tolist()\n",
    "    # Features for each drug, for example, when feature_name is target, drug_list=[\"P30556|P05412\",\"P28223|P46098|……\"]\n",
    "    for i in drug_list:\n",
    "        for each_feature in i.split(\"|\"):\n",
    "            if each_feature not in all_feature:\n",
    "                all_feature.append(each_feature)  # obtain all the features\n",
    "    #print(\"length of all feature is\", len(all_feature))\n",
    "    feature_matrix = np.zeros((len(drug_list), len(all_feature)), dtype=float)\n",
    "    df_feature = DataFrame(\n",
    "        feature_matrix, columns=all_feature\n",
    "    )  # Consrtuct feature matrices with key of dataframe\n",
    "    for i in range(len(drug_list)):\n",
    "        for each_feature in df[feature_name].iloc[i].split(\"|\"):\n",
    "            df_feature[each_feature].iloc[i] = 1\n",
    "\n",
    "    df_feature = np.array(df_feature)\n",
    "    sim_matrix = np.array(Jaccard(df_feature))\n",
    "    \n",
    "    #print(feature_name + \" len is:\" + str(len(sim_matrix[0])))\n",
    "    return sim_matrix\n",
    "\n",
    "\n",
    "def prepare(df_drug, feature_list, mechanism, action, drugA, drugB):\n",
    "    d_label = {}\n",
    "    d_feature = {}\n",
    "\n",
    "    # Transfrom the interaction event to number\n",
    "    d_event = []\n",
    "    for i in range(len(mechanism)):\n",
    "        d_event.append(mechanism[i] + \" \" + action[i])\n",
    "\n",
    "    count = {}\n",
    "    for i in d_event:\n",
    "        if i in count:\n",
    "            count[i] += 1\n",
    "        else:\n",
    "            count[i] = 1\n",
    "    event_num = len(count)\n",
    "    list1 = sorted(count.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i in range(len(list1)):\n",
    "        d_label[list1[i][0]] = i\n",
    "\n",
    "    vector = []\n",
    "    for i in feature_list:\n",
    "        #vector = np.hstack((vector, feature_vector(i, df_drug, vector_size)))\n",
    "        vector.append(feature_vector(i, df_drug))\n",
    "    vector = np.stack(vector, axis=-1)\n",
    "    # Transfrom the drug ID to feature vector\n",
    "    for i in range(len(np.array(df_drug[\"name\"]).tolist())):\n",
    "        d_feature[np.array(df_drug[\"name\"]).tolist()[i]] = vector[i]\n",
    "\n",
    "    # Use the dictionary to obtain feature vector and label\n",
    "    new_feature = []\n",
    "    new_label = []\n",
    "\n",
    "    for i in range(len(d_event)):\n",
    "        temp = np.concatenate([d_feature[drugA[i]][None], d_feature[drugB[i]][None]], axis=0)\n",
    "        new_feature.append(temp)\n",
    "        new_label.append(d_label[d_event[i]])\n",
    "\n",
    "    new_feature = np.array(new_feature)  # 323539*....\n",
    "    new_label = np.array(new_label)  # 323539\n",
    "\n",
    "    return new_feature, new_label, event_num\n",
    "\n",
    "\n",
    "df_drug = pd.read_csv(\"drug_features.csv\")\n",
    "extraction = pd.read_csv(\"extraction.csv\")\n",
    "mechanism = extraction[\"mechanism\"]\n",
    "action = extraction[\"action\"]\n",
    "drugA = extraction[\"drugA\"]\n",
    "drugB = extraction[\"drugB\"]\n",
    "feature_list = [\"pathway\", \"target\", \"enzyme\", \"category\"]\n",
    "new_feature, new_label, event_num = prepare(df_drug, feature_list, mechanism, action, drugA, drugB)\n",
    "new_feature = torch.tensor(new_feature, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_432489/2032577051.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.features = torch.tensor(features, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DrugInteractionDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]\n",
    "\n",
    "\n",
    "# Assuming new_feature and new_label are available as numpy arrays\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "features_train, features_val, labels_train, labels_val = train_test_split(\n",
    "    new_feature, new_label, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create dataset objects\n",
    "train_dataset = DrugInteractionDataset(features_train, labels_train)\n",
    "val_dataset = DrugInteractionDataset(features_val, labels_val)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNDDI(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNDDI, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 64, (3, 1), padding=(1, 0))\n",
    "        self.conv2 = nn.Conv2d(64, 128, (3, 1), padding=(1, 0))\n",
    "        self.conv3_1 = nn.Conv2d(128, 128, (3, 1), padding=(1, 0))\n",
    "        self.conv3_2 = nn.Conv2d(128, 128, (3, 1), padding=(1, 0))\n",
    "        self.conv4 = nn.Conv2d(128, 256, (3, 1), padding=(1, 0))\n",
    "        self.fc1 = nn.Linear(256 * 572 * 4, 256)  # Adjust feature_size based on your input dimensions\n",
    "        self.fc2 = nn.Linear(256, 65)  # Assuming 65 DDI types\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.conv2(x), negative_slope=0.2)\n",
    "        identity = x\n",
    "        x = F.leaky_relu(self.conv3_1(x), negative_slope=0.2)\n",
    "        x = self.conv3_2(x)\n",
    "        x += identity\n",
    "        x = F.leaky_relu(x, negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.conv4(x), negative_slope=0.2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.leaky_relu(self.fc1(x), negative_slope=0.2)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for features, labels in train_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, device, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    val_loss = total_loss / len(val_loader)\n",
    "    val_accuracy = correct / len(val_loader.dataset)\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, filename):\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(state, filename)\n",
    "    print(f\"Saved checkpoint: {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class focal_loss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super(focal_loss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, preds, labels):\n",
    "        labels = labels[..., None]\n",
    "\n",
    "        preds_logsoft = F.log_softmax(preds, dim=1)\n",
    "        preds_softmax = torch.exp(preds_logsoft)\n",
    "\n",
    "        preds_softmax = preds_softmax.gather(1, labels)\n",
    "        preds_logsoft = preds_logsoft.gather(1, labels)\n",
    "\n",
    "        loss = -torch.mul(torch.pow((1 - preds_softmax), self.gamma), preds_logsoft)\n",
    "\n",
    "        loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:21<17:16, 21.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.8764, Validation Loss: 0.3628, Validation Accuracy: 0.7918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:42<16:55, 21.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.2777, Validation Loss: 0.3381, Validation Accuracy: 0.8103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [01:03<16:40, 21.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.2173, Validation Loss: 0.2545, Validation Accuracy: 0.8415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [01:25<16:21, 21.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1825, Validation Loss: 0.2843, Validation Accuracy: 0.8480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [01:46<15:56, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1802, Validation Loss: 0.3486, Validation Accuracy: 0.8111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [02:07<15:33, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.1394, Validation Loss: 0.2700, Validation Accuracy: 0.8332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [02:28<15:09, 21.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.1302, Validation Loss: 0.2829, Validation Accuracy: 0.8444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [02:49<14:46, 21.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.1259, Validation Loss: 0.7220, Validation Accuracy: 0.7724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [03:10<14:25, 21.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.1296, Validation Loss: 0.2329, Validation Accuracy: 0.8791\n",
      "Epoch 10, Train Loss: 0.1721, Validation Loss: 0.3235, Validation Accuracy: 0.8584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [03:32<14:15, 21.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: checkpoints/cnn_ddi_epoch_10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [03:53<13:49, 21.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train Loss: 0.0829, Validation Loss: 0.2793, Validation Accuracy: 0.8642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [04:14<13:24, 21.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 0.0824, Validation Loss: 0.3565, Validation Accuracy: 0.8449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [04:35<12:59, 21.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Train Loss: 0.1575, Validation Loss: 0.2600, Validation Accuracy: 0.8799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [04:56<12:37, 21.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train Loss: 0.0683, Validation Loss: 0.4144, Validation Accuracy: 0.8617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [05:17<12:18, 21.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Train Loss: 0.1668, Validation Loss: 0.2761, Validation Accuracy: 0.8830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [05:38<11:59, 21.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 0.0571, Validation Loss: 0.5085, Validation Accuracy: 0.8504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [06:00<11:39, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Train Loss: 0.2301, Validation Loss: 0.3286, Validation Accuracy: 0.8904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [06:21<11:19, 21.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Train Loss: 0.0273, Validation Loss: 0.3865, Validation Accuracy: 0.8948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [06:42<10:57, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Train Loss: 0.1896, Validation Loss: 0.3755, Validation Accuracy: 0.8772\n",
      "Epoch 20, Train Loss: 0.0736, Validation Loss: 0.5849, Validation Accuracy: 0.8524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [07:04<10:43, 21.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: checkpoints/cnn_ddi_epoch_20.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [07:26<10:21, 21.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Train Loss: 0.1162, Validation Loss: 0.5393, Validation Accuracy: 0.8696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [07:47<10:02, 21.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Train Loss: 0.1656, Validation Loss: 1.9225, Validation Accuracy: 0.8199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [08:09<09:41, 21.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Train Loss: 0.1321, Validation Loss: 0.4515, Validation Accuracy: 0.8943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [08:30<09:19, 21.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Train Loss: 0.0484, Validation Loss: 0.5903, Validation Accuracy: 0.8609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [08:52<08:59, 21.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Train Loss: 0.3441, Validation Loss: 0.7192, Validation Accuracy: 0.8810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [09:14<08:37, 21.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Train Loss: 0.0449, Validation Loss: 0.6276, Validation Accuracy: 0.8878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [09:35<08:14, 21.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Train Loss: 0.1506, Validation Loss: 1.3008, Validation Accuracy: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [09:56<07:51, 21.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Train Loss: 0.1009, Validation Loss: 0.6668, Validation Accuracy: 0.8878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [10:17<07:28, 21.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Train Loss: 0.1041, Validation Loss: 1.5599, Validation Accuracy: 0.8760\n",
      "Epoch 30, Train Loss: 0.1621, Validation Loss: 0.7454, Validation Accuracy: 0.8979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [10:39<07:11, 21.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: checkpoints/cnn_ddi_epoch_30.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [11:01<06:47, 21.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Train Loss: 1.8079, Validation Loss: 3.4827, Validation Accuracy: 0.8606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [11:23<06:28, 21.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Train Loss: 0.2704, Validation Loss: 1.3963, Validation Accuracy: 0.8874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [11:44<06:08, 21.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Train Loss: 0.0645, Validation Loss: 1.8864, Validation Accuracy: 0.8949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [12:06<05:44, 21.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Train Loss: 0.1498, Validation Loss: 1.7150, Validation Accuracy: 0.8868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [12:27<05:21, 21.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Train Loss: 0.1347, Validation Loss: 1.8790, Validation Accuracy: 0.8929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [12:48<04:58, 21.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Train Loss: 0.3852, Validation Loss: 3.6643, Validation Accuracy: 0.8473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [13:09<04:38, 21.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Train Loss: 0.2350, Validation Loss: 1.4745, Validation Accuracy: 0.8945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [13:31<04:16, 21.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Train Loss: 0.0951, Validation Loss: 1.3499, Validation Accuracy: 0.9035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [13:52<03:55, 21.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Train Loss: 0.2292, Validation Loss: 1.7378, Validation Accuracy: 0.8943\n",
      "Epoch 40, Train Loss: 0.1413, Validation Loss: 1.7385, Validation Accuracy: 0.8860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [14:14<03:35, 21.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: checkpoints/cnn_ddi_epoch_40.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [14:36<03:13, 21.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Train Loss: 0.2066, Validation Loss: 2.9963, Validation Accuracy: 0.8704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [14:57<02:51, 21.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Train Loss: 0.1928, Validation Loss: 2.5624, Validation Accuracy: 0.8849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [15:18<02:29, 21.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Train Loss: 0.2186, Validation Loss: 2.3761, Validation Accuracy: 0.8835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [15:39<02:08, 21.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Train Loss: 0.1952, Validation Loss: 3.4227, Validation Accuracy: 0.8682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [16:01<01:47, 21.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Train Loss: 0.1683, Validation Loss: 1.7532, Validation Accuracy: 0.8894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [16:22<01:25, 21.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Train Loss: 0.1699, Validation Loss: 3.0286, Validation Accuracy: 0.8941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [16:44<01:04, 21.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Train Loss: 0.3965, Validation Loss: 2.1042, Validation Accuracy: 0.8982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [17:05<00:42, 21.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Train Loss: 0.0912, Validation Loss: 2.0154, Validation Accuracy: 0.8968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [17:26<00:21, 21.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Train Loss: 0.2051, Validation Loss: 2.6824, Validation Accuracy: 0.9033\n",
      "Epoch 50, Train Loss: 0.2484, Validation Loss: 2.6757, Validation Accuracy: 0.8936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [17:49<00:00, 21.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: checkpoints/cnn_ddi_epoch_50.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNDDI().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = focal_loss()\n",
    "\n",
    "num_epochs = 50\n",
    "checkpoint_interval = 10\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train_loss = train(model, device, train_loader, optimizer, criterion)\n",
    "    val_loss, val_accuracy = validate(model, device, val_loader, criterion)\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    if (epoch + 1) % checkpoint_interval == 0 or (epoch + 1) == num_epochs:\n",
    "        save_checkpoint(model, optimizer, epoch + 1, f'checkpoints/cnn_ddi_epoch_{epoch+1}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://huggingface.co/conrevo/CS598-CNN-DDI/resolve/main/cnn_ddi_epoch_50.pt\" to checkpoints/cnn_ddi_epoch_50.pt\n",
      "100%|██████████| 1.68G/1.68G [00:27<00:00, 66.1MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_ddi = CNNDDI()\n",
    "state_dict = torch.hub.load_state_dict_from_url(\"https://huggingface.co/conrevo/CS598-CNN-DDI/resolve/main/cnn_ddi_epoch_50.pt\", model_dir=\"checkpoints\")\n",
    "cnn_ddi.load_state_dict(state_dict[\"state_dict\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
